{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = os.listdir(\"./DATA/np_data\")[1:500]\n",
    "uids = list(set([fname.split('.')[0] for fname in files]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Конвертация монофонных выравниваний в трифонные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала нужно отрезать от фонем суффиксы \\__B_, \\__I_, \\__E_, \\__S_, потому что они означают _начало_, _конец_ и т.д., и  соответственно, они нам не очень нужны. <br>\n",
    "И сразу же делаем словарь, где в качестве ключа выступает индекс (или номер) фонемы согласно файлу, а в качестве значения сама фонема."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictionary = {}\n",
    "with open('./DATA/data/lang/phones.txt') as fin:\n",
    "    reader = csv.reader(fin, delimiter=' ')\n",
    "    for row in reader:\n",
    "        dictionary[int(row[1])] = row[0].split('_')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы конвертировать монофоны в трифоны, нужно сначала сгруппировать фонемы, потом найти уникальные группы в группах, создать трифоны из этих групп и заменить номера фонем самими фонемами. Для первых фонем и последних трифоны создавать не нужно, заменим их просто на SIL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_triphones(uid):\n",
    "    targs = np.load('./DATA/np_data/' + uid + '.targs.npy')\n",
    "    phones = []\n",
    "    temp = []\n",
    "    for phone in targs:\n",
    "        if temp and phone not in temp:\n",
    "            phones.append(temp)\n",
    "            temp = []\n",
    "        temp.append(phone)\n",
    "    \n",
    "    phones.append(temp)\n",
    "    \n",
    "    unique = [x[0] for x in phones]\n",
    "    triphones = [unique[i:i+3] for i in range(len(unique)-3+1)]\n",
    "    #print(triphones)\n",
    "    result = []\n",
    "    result += phones.pop(0)\n",
    "\n",
    "    for i in range(len(phones)-1):\n",
    "        result += ['_'.join([dictionary[x] for x in triphones[i]]) for _ in range(len(phones[i]))]\n",
    "    result += phones[-1]\n",
    "    \n",
    "    for n, i in enumerate(result):\n",
    "        if i == 1:\n",
    "            result[n] = 'SIL'\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем вектора с признаками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_vectors(uid):\n",
    "    feats = np.load('DATA/np_data/' + uid + '.feats.npy')\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем каждый файл, делаем конфертацию и загрузку признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_triphones_vectors():\n",
    "    triphones_vectors = defaultdict(list)\n",
    "    \n",
    "    for uid in uids:\n",
    "        triphones = convert_to_triphones(uid)\n",
    "        vectors = load_vectors(uid)\n",
    "\n",
    "        for i in range(len(triphones)):\n",
    "            triphones_vectors[triphones[i]].append(vectors[i])\n",
    "    \n",
    "    return triphones_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "triphs_vecs = make_triphones_vectors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Оценка параметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь для каждого трифона нужно оценить mean и std. Конкатенируем их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "triphones_estimation = {}\n",
    "for triph in triphs_vecs.keys():\n",
    "    mean = np.mean(triphs_vecs[triph], axis=0)\n",
    "    std = np.std(triphs_vecs[triph], axis=0)\n",
    "    triphones_estimation[triph] = np.append(mean, std, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "triphs = list(triphones_estimation.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для кластеризации выбираем трифоны с общей фонемой посередине. Пусть общей фонемой будет <b>AH0</b>. По IPA это <b>ə</b>. Примеры употребления: _sofa_ (S OW1 F AH0), _alone_ (AH0 L OW1 N)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AH_triphones = []\n",
    "for x in triphs:\n",
    "    if \"_\" in x:\n",
    "        if x.split(\"_\")[1] == \"AH0\":\n",
    "            AH_triphones.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array([triphones_estimation[AH_triphones[i]] for i in range(len(AH_triphones))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запускаем функцию для кластеризации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(copy_x=True, init='k-means++', max_iter=300, n_clusters=10, n_init=10,\n",
       "    n_jobs=1, precompute_distances='auto', random_state=None, tol=0.0001,\n",
       "    verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(10)\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clusters = defaultdict(list)\n",
    "for i in list(zip(kmeans.labels_, AH_triphones)):\n",
    "    clusters[i[0]].append(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: ['D_AH0_SIL', 'D_AH0_HH', 'TH_AH0_HH', 'NG_AH0_K', 'M_AH0_SIL', 'IY1_AH0_N', 'R_AH0_SIL', 'K_AH0_SIL', 'N_AH0_EU0', 'R_AH0_R', 'M_AH0_AO1', 'ZH_AH0_SIL', 'IY0_AH0_SIL'] \n",
      "\n",
      "Cluster 1: ['F_AH0_B', 'T_AH0_W', 'CH_AH0_L', 'S_AH0_L', 'K_AH0_L', 'T_AH0_L', 'Z_AH0_L', 'F_AH0_L', 'P_AH0_L', 'B_AH0_L', 'S_AH0_R', 'DH_AH0_W', 'SH_AH0_L', 'T_AH0_R', 'Z_AH0_B', 'V_AH0_L', 'G_AH0_L', 'D_AH0_L', 'JH_AH0_L', 'G_AH0_B'] \n",
      "\n",
      "Cluster 2: ['P_AH0_S', 'NG_AH0_S', 'L_AH0_S', 'DH_AH0_CH', 'S_AH0_TH', 'UW0_AH0_S', 'DH_AH0_F', 'S_AH0_Z', 'D_AH0_F', 'D_AH0_TH', 'TH_AH0_S', 'Z_AH0_F', 'V_AH0_S', 'S_AH0_F', 'T_AH0_F', 'EY1_AH0_S', 'R_AH0_S', 'DH_AH0_SIL', 'S_AH0_S', 'K_AH0_S', 'AY1_AH0_S', 'Z_AH0_Z', 'T_AH0_CH', 'IY0_AH0_S', 'DH_AH0_TH', 'SH_AH0_S', 'NG_AH0_F', 'Z_AH0_S', 'IY1_AH0_F', 'L_AH0_TH', 'D_AH0_S', 'HH_AH0_Z', 'W_AH0_Z', 'G_AH0_S', 'F_AH0_S', 'K_AH0_Z', 'N_AH0_F', 'T_AH0_T', 'W_AH0_S', 'T_AH0_S', 'UW1_AH0_F', 'N_AH0_S', 'JH_AH0_S', 'M_AH0_S', 'CH_AH0_F', 'OY1_AH0_S', 'DH_AH0_S'] \n",
      "\n",
      "Cluster 3: ['P_AH0_K', 'V_AH0_M', 'SH_AH0_P', 'Y_AH0_L', 'CH_AH0_Z', 'Z_AH0_M', 'D_AH0_V', 'DH_AH0_L', 'M_AH0_N', 'N_AH0_D', 'D_AH0_Z', 'DH_AH0_HH', 'V_AH0_K', 'AY1_AH0_R', 'M_AH0_B', 'T_AH0_HH', 'D_AH0_N', 'R_AH0_B', 'M_AH0_F', 'R_AH0_M', 'TH_AH0_M', 'DH_AH0_R', 'D_AH0_D', 'D_AH0_R', 'NG_AH0_R', 'F_AH0_M', 'N_AH0_B', 'DH_AH0_Z', 'L_AH0_N', 'G_AH0_T', 'K_AH0_T', 'K_AH0_K', 'NG_AH0_G', 'N_AH0_N', 'L_AH0_M', 'TH_AH0_D', 'B_AH0_N', 'DH_AH0_V', 'R_AH0_N', 'L_AH0_G', 'D_AH0_B', 'M_AH0_D', 'NG_AH0_B', 'D_AH0_M', 'AY1_AH0_N', 'N_AH0_M', 'Z_AH0_JH', 'Z_AH0_R', 'T_AH0_V', 'IY0_AH0_N', 'S_AH0_M', 'V_AH0_V', 'D_AH0_IH0', 'NG_AH0_N', 'V_AH0_P'] \n",
      "\n",
      "Cluster 4: ['P_AH0_W', 'L_AH0_B', 'UW1_AH0_P', 'AY1_AH0_L', 'V_AH0_W', 'M_AH0_W', 'UW0_AH0_L', 'R_AH0_L', 'N_AH0_V', 'IY0_AH0_W', 'AY1_AH0_W', 'M_AH0_R', 'N_AH0_W', 'OY1_AH0_L', 'B_AH0_B', 'M_AH0_L', 'W_AH0_L', 'V_AH0_HH', 'OW1_AH0_M', 'AW1_AH0_L', 'N_AH0_R', 'IY1_AH0_L', 'N_AH0_L', 'L_AH0_P', 'D_AH0_W', 'UW1_AH0_L', 'EY1_AH0_W', 'L_AH0_L', 'NG_AH0_L', 'UW1_AH0_R'] \n",
      "\n",
      "Cluster 5: ['IY1_AH0_T', 'AY1_AH0_P', 'IY1_AH0_G', 'AY1_AH0_T', 'D_AH0_G', 'NG_AH0_D', 'IY0_AH0_B', 'K_AH0_TH', 'N_AH0_G', 'AY1_AH0_D', 'IY1_AH0_M', 'IY0_AH0_D', 'D_AH0_K', 'Y_AH0_N', 'AY1_AH0_M', 'IY1_AH0_P', 'N_AH0_K', 'IY0_AH0_V', 'M_AH0_G', 'IY0_AH0_F', 'IY1_AH0_K', 'IY0_AH0_M'] \n",
      "\n",
      "Cluster 6: ['DH_AH0_P', 'L_AH0_T', 'DH_AH0_K', 'DH_AH0_JH', 'OW1_AH0_T', 'T_AH0_P', 'TH_AH0_K', 'IY0_AH0_K', 'R_AH0_P', 'V_AH0_D', 'B_AH0_T', 'L_AH0_JH', 'DH_AH0_G', 'DH_AH0_D', 'IY0_AH0_P', 'N_AH0_P', 'L_AH0_K', 'IY0_AH0_T', 'Y_AH0_P', 'V_AH0_T', 'R_AH0_JH', 'D_AH0_T', 'DH_AH0_T', 'M_AH0_T', 'R_AH0_T', 'R_AH0_D', 'N_AH0_T', 'D_AH0_P'] \n",
      "\n",
      "Cluster 7: ['SIL_AH0_P', 'SIL_AH0_K', 'SIL_AH0_R', 'SIL_AH0_W', 'SIL_AH0_M', 'SIL_AH0_N', 'SIL_AH0_B', 'T_AH0_AE1', 'SIL_AH0_F', 'SIL_AH0_HH', 'SIL_AH0_T', 'SIL_AH0_D', 'SIL_AH0_CH', 'SIL_AH0_G', 'SIL_AH0_L', 'P_AH0_T', 'SIL_AH0_V', 'SIL_AH0_S'] \n",
      "\n",
      "Cluster 8: ['G_AH0_N', 'F_AH0_N', 'JH_AH0_N', 'SH_AH0_N', 'T_AH0_N', 'Z_AH0_V', 'T_AH0_K', 'T_AH0_G', 'CH_AH0_P', 'ZH_AH0_N', 'T_AH0_M', 'P_AH0_N', 'T_AH0_D', 'JH_AH0_G', 'K_AH0_N', 'CH_AH0_D', 'Z_AH0_K', 'CH_AH0_N', 'T_AH0_DH', 'ZH_AH0_L', 'S_AH0_N', 'T_AH0_B', 'DH_AH0_N', 'Z_AH0_N', 'S_AH0_B', 'DH_AH0_B', 'K_AH0_M', 'K_AH0_B', 'Z_AH0_T', 'Z_AH0_P', 'S_AH0_P', 'TH_AH0_N', 'S_AH0_V', 'K_AH0_G', 'S_AH0_K', 'DH_AH0_M', 'V_AH0_N', 'S_AH0_T'] \n",
      "\n",
      "Cluster 9: ['R_AH0_F', 'R_AH0_K', 'R_AH0_V', 'L_AH0_F', 'M_AH0_CH'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in clusters:\n",
    "    print(\"Cluster {}:\".format(i), clusters[i], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AH0 (ə) представляет собой результат редукции, что означает ослабление гласных в безударном положении. Ноль в обозначении фонемы AH0 (ə) означает безударный звук. <br>\n",
    "Кластер #0 достаточно хороший. Фонема часто стоит в конце слова (на письме отображается диграфами or/er/r). Т.е. в целом понятно, по какому принципу сгруппированы трифоны.<br>\n",
    "Тоже самое можно сказать и про кластер #7, потому что в безударном положении в начале слова буквы a/o тоже передаются звуком AH0 (ə). <br>\n",
    "Остальные кластеры сложно проверить \"на глаз\", потому что звук AH0 (ə) встречается в безударном слоге в середине большого числа слов, и особого правила для этого не существует.<br>\n",
    "В кластере #2 в большинстве трифонов за AH0 (ə) следует или фрикативные (щелевые) согласные F,S,Z,TH или аффрикат CH.<br>\n",
    "В кластере #3 за звуком AH0 (ə) идут как взрывные согласные, так и носовые сонанты.<br>\n",
    "В кластере #6 за фонемой следуют только AH0 (ə) только взрывные согласные.<br>\n",
    "Кластеры #4, #5, #7, #8 и #9 включают себе разные группы фонем, которые следуют после AH0 (ə). Поэтому не совсем явно, по какому принципу трифоны оказались в рдном кластере.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
